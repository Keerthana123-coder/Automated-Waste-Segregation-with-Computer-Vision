{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Keerthana123-coder/Automated-Waste-Segregation-with-Computer-Vision/blob/main/AI_Powered_Waste_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Waste classification Model**"
      ],
      "metadata": {
        "id": "83CDtFUIYkG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NV2WpUJtQD9E",
        "outputId": "6554006a-8a32-46d3-c5b3-ebd792de6953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from keras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras) (0.5.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from optree->keras) (4.15.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Install packages***"
      ],
      "metadata": {
        "id": "ozF1PYI4Y3nZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "import glob\n",
        "import tqdm\n",
        "import os\n",
        "\n",
        "from tqdm import tqdm\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from seaborn import heatmap\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Conv2D, Lambda, MaxPooling2D, Dense, Dropout, Flatten # convolution layers & core layers\n",
        "\n",
        "from keras.layers import BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, History"
      ],
      "metadata": {
        "id": "4rD9VAFUPtPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqEugOiOUcm0",
        "outputId": "6a9cc3e1-4f4e-468f-ff39-bc6e8adb72c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data structure**"
      ],
      "metadata": {
        "id": "PTI2SbXNZGrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display.Image('Resources/Images/waste_data_structure.jpeg', width = 550, height = 250)"
      ],
      "metadata": {
        "id": "zFSzLv3RWASR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = \"Resources/Dataset\"\n",
        "train_dir = os.path.join(base_dir, \"Train\")\n",
        "test_dir = os.path.join(base_dir, \"Test\")"
      ],
      "metadata": {
        "id": "balZ7X3GWMl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_o = glob.glob(os.path.join(train_dir, 'O', '*.jpg'))\n",
        "train_r = glob.glob(os.path.join(train_dir, 'R', '*.jpg'))\n",
        "\n",
        "a = len(train_o)\n",
        "b = len(train_r)\n",
        "\n",
        "print(\"Number of training samples: {}\".format(a+b))"
      ],
      "metadata": {
        "id": "XccpEFVLWQlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Os path join (test)\n",
        "\n",
        "test_o = glob.glob(os.path.join(test_dir, 'O', '*.jpg'))\n",
        "test_r = glob.glob(os.path.join(test_dir, 'R', '*.jpg'))\n",
        "\n",
        "a = len(test_o)\n",
        "b = len(test_r)\n",
        "\n",
        "\n",
        "print(\"Number of test samples: {}\".format(a+b))"
      ],
      "metadata": {
        "id": "9XU2IBqrWW7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Augumentation**"
      ],
      "metadata": {
        "id": "itehnq7hZMso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Datagenerators\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1.0 / 255.0,\n",
        "                                   zoom_range = 0.4,\n",
        "                                   rotation_range = 10,\n",
        "                                   horizontal_flip = True,\n",
        "                                   vertical_flip = True,\n",
        "                                   validation_split = 0.2)\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale = 1.0 / 255.0,\n",
        "                                   validation_split = 0.2)\n",
        "\n",
        "test_datagen  = ImageDataGenerator(rescale = 1.0 / 255.0)"
      ],
      "metadata": {
        "id": "TYyvcO7gWaCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Training**"
      ],
      "metadata": {
        "id": "a5PJ0JjZZRs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train dataset\n",
        "\n",
        "train_ds  = train_datagen.flow_from_directory(directory = train_dir,\n",
        "                                                   target_size = (180, 180),\n",
        "                                                   class_mode = 'categorical',\n",
        "                                                   batch_size = 32,\n",
        "                                                   subset = 'training')"
      ],
      "metadata": {
        "id": "euwsqSqPWdpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Validating Dataset**"
      ],
      "metadata": {
        "id": "SArbdpMKZV-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate dataset\n",
        "\n",
        "valid_ds = valid_datagen.flow_from_directory(directory = train_dir,\n",
        "                                                  target_size = (180, 180),\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  batch_size = 32,\n",
        "                                                  subset = 'validation')"
      ],
      "metadata": {
        "id": "Bck30o1wWg03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing Dataset**"
      ],
      "metadata": {
        "id": "LQC1UjK5ZaJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test dataset\n",
        "\n",
        "test_ds = test_datagen.flow_from_directory(directory = test_dir,\n",
        "                                                  target_size = (180, 180),\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  batch_size = 32,\n",
        "                                                  shuffle=False)"
      ],
      "metadata": {
        "id": "OtP4bkX5Wk6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check classes\n",
        "\n",
        "print(train_ds.class_indices)\n",
        "print(test_ds.class_indices)"
      ],
      "metadata": {
        "id": "-y6An2sZWm7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Viewing images\n",
        "\n",
        "fig, ax = plt.subplots(nrows = 2, ncols = 5, figsize = (12,6))\n",
        "#plt.subplots_adjust(hspace=0.55)\n",
        "\n",
        "for i in range(2):\n",
        "    for j in range(5):\n",
        "        rand1 = np.random.randint(len(train_ds))\n",
        "        rand2 = np.random.randint(32)\n",
        "        ax[i,j].imshow(train_ds[rand1][0][rand2])\n",
        "        ax[i,j].axis('off')\n",
        "        label = train_ds[rand1][1][rand2]\n",
        "        # print(label[0])\n",
        "        if label[0] == 0:\n",
        "            ax[i,j].set_title('Recycle Waste')\n",
        "        else:\n",
        "            ax[i,j].set_title('Organic Waste')\n",
        "\n",
        "plt.tight_layout\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6WVRoJhYWslJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building The Model**"
      ],
      "metadata": {
        "id": "jxs-dwaGZfne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining callbacks\n",
        "\n",
        "filepath = './final_model_weights.hdf5'\n",
        "\n",
        "earlystopping = EarlyStopping(monitor = 'val_auc',\n",
        "                              mode = 'max' ,\n",
        "                              patience = 5,\n",
        "                              verbose = 1)\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath,\n",
        "                                monitor = 'val_auc',\n",
        "                                mode='max',\n",
        "                                save_best_only=True,\n",
        "                                verbose = 1)\n",
        "\n",
        "\n",
        "callback_list = [earlystopping, checkpoint]"
      ],
      "metadata": {
        "id": "17LLUWo3WvrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Base Model(VGG16)**"
      ],
      "metadata": {
        "id": "6eYJwMeRZmbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Base model\n",
        "\n",
        "base_model = VGG16(input_shape=(180,180,3),\n",
        "                   include_top=False,\n",
        "                   weights=\"imagenet\")"
      ],
      "metadata": {
        "id": "r7z7Mb8yWx4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freezing layers\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable=False"
      ],
      "metadata": {
        "id": "zIqMNHFgW0L2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show vgg model summary\n",
        "base_model.summary()"
      ],
      "metadata": {
        "id": "bVkc_EcUW2hB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualizing Base Model Layers With Test Images**"
      ],
      "metadata": {
        "id": "IgsbhlJ3ZycM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate thru all the layers of the model\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    if 'conv' in layer.name:\n",
        "        weights, bias= layer.get_weights()\n",
        "        # filters, biases = layer.get_weights()\n",
        "        print(layer.name)\n",
        "        # print(layer.name, filters.shape)\n",
        "        # normalize filter values between  0 and 1 for visualization\n",
        "        f_min, f_max = weights.min(), weights.max()\n",
        "        filters = (weights - f_min) / (f_max - f_min)\n",
        "        print(filters.shape[3])\n",
        "        filter_cnt=1\n",
        "        # plotting all the filters\n",
        "        for i in range(filters.shape[3]):\n",
        "            # get the filters\n",
        "            filt=filters[:,:,:, i]\n",
        "            # plotting each of the channel, color image RGB channels\n",
        "            for j in range(filters.shape[0]):\n",
        "                ax = plt.subplot(filters.shape[3], filters.shape[0], filter_cnt)\n",
        "                ax.set_xticks([])\n",
        "                ax.set_yticks([])\n",
        "                plt.imshow(filt[:,:, j])\n",
        "                filter_cnt+=1\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "vVJUHhnSXFfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize feature maps for an organic image\n",
        "\n",
        "# Image path\n",
        "img_path=test_dir + '/O' + '/O_12825.jpg'\n",
        "\n",
        "# Define a new model, input=image\n",
        "# Output=intermediate representations for all layers in the previous model after the first\n",
        "successive_outputs = [layer.output for layer in base_model.layers[1:]]\n",
        "\n",
        "# Visualization_model = Model(img_input, successive_outputs)\n",
        "visualization_model = tf.keras.models.Model(inputs = base_model.input, outputs = successive_outputs)\n",
        "\n",
        "# Load the input image\n",
        "img = load_img(img_path, target_size=(180, 180))\n",
        "\n",
        "# Convert ht image to Array of dimension (180,180,3)\n",
        "x = img_to_array(img)\n",
        "x = x.reshape((1,) + x.shape)\n",
        "\n",
        "# Rescale by 1/255\n",
        "x /= 255.0\n",
        "\n",
        "# Run input image through our visualization network to obtain all intermediate representations for the image\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "\n",
        "# Retrieve the names of the layers, so we can have them as part of our plot\n",
        "layer_names = [layer.name for layer in base_model.layers]\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "  print(feature_map.shape)\n",
        "  if len(feature_map.shape) == 4:\n",
        "\n",
        "    # Plot Feature maps for the conv / maxpool layers, not the fully-connected layers\n",
        "    n_features = feature_map.shape[-1]  # number of features in the feature map\n",
        "    size = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n",
        "\n",
        "    # Tile our images in a matrix\n",
        "    display_grid = np.zeros((size, size * n_features))\n",
        "\n",
        "    # Postprocess the feature to be visually palatable\n",
        "    for i in range(n_features):\n",
        "      x  = feature_map[0, :, :, i]\n",
        "      x -= x.mean()\n",
        "      x /= x.std ()\n",
        "      x *=  64\n",
        "      x += 128\n",
        "      x  = np.clip(x, 0, 255).astype('uint8')\n",
        "\n",
        "      # Tile each filter into a horizontal grid\n",
        "      display_grid[:, i * size : (i + 1) * size] = x\n",
        "\n",
        "# Display the grid\n",
        "    scale = 20. / n_features\n",
        "    plt.figure(figsize=(scale * n_features*5, scale*4))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='bwr' )\n",
        "\n",
        "# Disable tf warning\n",
        "logging.getLogger('tensorflow').disabled = True"
      ],
      "metadata": {
        "id": "B8hp40-KXI3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize feature maps for a recycled image\n",
        "\n",
        "# Image path\n",
        "img_path=test_dir + '/R' + '/R_11107.jpg'\n",
        "\n",
        "# Define a new model, input=image\n",
        "# Output=intermediate representations for all layers in the previous model after the first\n",
        "successive_outputs = [layer.output for layer in base_model.layers[1:]]\n",
        "\n",
        "# Visualization_model = Model(img_input, successive_outputs)\n",
        "visualization_model = tf.keras.models.Model(inputs = base_model.input, outputs = successive_outputs)\n",
        "\n",
        "# Load the input image\n",
        "img = load_img(img_path, target_size=(180, 180))\n",
        "\n",
        "# Convert ht image to Array of dimension (180,180,3)\n",
        "x = img_to_array(img)\n",
        "x = x.reshape((1,) + x.shape)\n",
        "\n",
        "# Rescale by 1/255\n",
        "x /= 255.0\n",
        "\n",
        "# Run input image through our visualization network to obtain all intermediate representations for the image\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "\n",
        "# Retrieve the names of the layers, so we can have them as part of our plot\n",
        "layer_names = [layer.name for layer in base_model.layers]\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "  print(feature_map.shape)\n",
        "  if len(feature_map.shape) == 4:\n",
        "\n",
        "    # Plot Feature maps for the conv / maxpool layers, not the fully-connected layers\n",
        "\n",
        "    n_features = feature_map.shape[-1]  # number of features in the feature map\n",
        "    size = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n",
        "\n",
        "    # We will tile our images in this matrix\n",
        "    display_grid = np.zeros((size, size * n_features))\n",
        "\n",
        "    # Postprocess the feature to be visually palatable\n",
        "    for i in range(n_features):\n",
        "      x  = feature_map[0, :, :, i]\n",
        "      x -= x.mean()\n",
        "      x /= x.std ()\n",
        "      x *=  64\n",
        "      x += 128\n",
        "      x  = np.clip(x, 0, 255).astype('uint8')\n",
        "\n",
        "      # Tile each filter into a horizontal grid\n",
        "      display_grid[:, i * size : (i + 1) * size] = x\n",
        "\n",
        "# Display the grid\n",
        "    scale = 20. / n_features\n",
        "    plt.figure( figsize=(scale * n_features*5, scale*4) )\n",
        "    plt.title ( layer_name )\n",
        "    plt.grid  ( False )\n",
        "    plt.imshow( display_grid, aspect='auto', cmap='bwr' )\n",
        "\n",
        "# Ignore Runtimewarning\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "tQolUZcYXLjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding to the Base Model -  Building Dense Layers"
      ],
      "metadata": {
        "id": "9c-CAOcYate3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Layers\n",
        "model=Sequential()\n",
        "model.add(base_model)\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add dense layers\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(5000,activation=\"relu\",kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1000,activation=\"relu\",kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(500,activation=\"relu\",kernel_initializer='he_uniform'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(2,activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "9CE8FtR1XTPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show model summary (with custom layers)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "5zd_drIgXVRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training Model**"
      ],
      "metadata": {
        "id": "vuPM1_25bCFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model fit (training)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[tf.keras.metrics.AUC(name = 'auc')])\n",
        "model_history = model.fit(train_ds, epochs=20, validation_data=valid_ds, callbacks = callback_list, verbose = 1)"
      ],
      "metadata": {
        "id": "Z8vprtNdXXXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing loss and accuracy values into a DataFrame to save permanently for plots\n",
        "\n",
        "# Store model.fit results in a variable\n",
        "history = model_history\n",
        "\n",
        "# Save as DataFrame:\n",
        "history_df = pd.DataFrame(history.history)\n",
        "history_df"
      ],
      "metadata": {
        "id": "2us-t-IiXaOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save as csv\n",
        "history_df.to_csv('Resources/Model/model_history.csv', index=False)"
      ],
      "metadata": {
        "id": "ko6jMGuHXemx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import csv\n",
        "model_history = pd.read_csv ('Resources/Model/model_history.csv')\n",
        "model_history"
      ],
      "metadata": {
        "id": "-01hXKHSXqF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot model loss\n",
        "\n",
        "plt.figure(figsize=(12,7))\n",
        "plt.plot(model_history['loss'], color='deeppink', linewidth=4)\n",
        "plt.plot(model_history['val_loss'], color='dodgerblue', linewidth=4)\n",
        "plt.title('Model Loss', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Loss', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Epoch', fontsize=14, fontweight='bold')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left', bbox_to_anchor=(1,1), fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FgfPiINGXt3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the model accuracy\n",
        "\n",
        "plt.figure(figsize=(12,7))\n",
        "plt.plot(model_history['auc'], color='deeppink', linewidth=4)\n",
        "plt.plot(model_history['val_auc'], color='dodgerblue', linewidth=4)\n",
        "plt.title('Model Accuracy', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Accuracy', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Epoch', fontsize=14, fontweight='bold')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left', bbox_to_anchor=(1,1), fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "XyyHBd54Xv8e",
        "outputId": "78a12b22-24ed-40a4-9691-391f98cb6e5a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1347911132.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'auc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'deeppink'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_auc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dodgerblue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bold'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_history' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x700 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Evaluation**"
      ],
      "metadata": {
        "id": "DXUcTBVPbI7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate overall loss and accuracy for test data\n",
        "model.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "cCcJ-z6rXzYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store final values as variables\n",
        "\n",
        "loss_final = 0.3659922480583191\n",
        "auc_final = 0.9392455220222473\n",
        "print(f\"The final loss was {loss_final}, and the final accuracy was {auc_final}.\")"
      ],
      "metadata": {
        "id": "zaA9iDSHX2fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classification Report**"
      ],
      "metadata": {
        "id": "ECONZWPMbRGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix and Classification Report\n",
        "\n",
        "metrics=tf.keras.metrics.AUC(name = 'auc')\n",
        "\n",
        "num_of_test_samples = 2513\n",
        "batch_size = 32\n",
        "\n",
        "Y_pred = model.predict(test_ds, num_of_test_samples // batch_size+1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(test_ds.classes, y_pred))\n",
        "print('Classification Report')\n",
        "target_names = ['Organic', 'Recycled']\n",
        "print(classification_report(test_ds.classes, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "id": "Sq7cf7xDX5vJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the classification report\n",
        "\n",
        "# Put data into a 2D array\n",
        "data = np.array([[.82, .90],\n",
        "                 [.94, .74],\n",
        "                [.88, .81]])\n",
        "\n",
        "# Plot the heatmap\n",
        "yticklabels = ['Precision', 'Recall', 'F1']\n",
        "xticklabels = ['Organic', 'Recycled']\n",
        "fig, ax = plt.subplots(figsize=(12,8))\n",
        "ax = sns.heatmap(data, xticklabels=xticklabels, yticklabels=yticklabels, annot=True, cmap='Blues')\n",
        "ax.set_title(\"Classification Report\", fontsize=14, fontweight='bold')"
      ],
      "metadata": {
        "id": "B1EOFhm-X7sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **True & False Positives**"
      ],
      "metadata": {
        "id": "h-WsS_AibY8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing scientific notation in the heatmap\n",
        "\n",
        "np.set_printoptions(suppress=True, threshold=2000)"
      ],
      "metadata": {
        "id": "6xeYU9qsX92U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix plot\n",
        "\n",
        "# Converting integers to percents\n",
        "perc1 = round(1314/1401*100,2)\n",
        "perc2 = round(87/1401*100,2)\n",
        "perc3 = round(288/1112*100,2)\n",
        "perc4 = round(824/1112*100,2)\n",
        "\n",
        "# Put data into a 2D array\n",
        "data = np.array([[perc1, perc2],\n",
        "                [perc3, perc4]])\n",
        "\n",
        "text = np.array([['% Predicted as Organic Correctly', '% Predicted as Organic Incorrectly'],\n",
        "                ['% Predicted as Recycled Incorrectly', '% Predicted as Recycled Correctly']])\n",
        "\n",
        "# Combine text with values\n",
        "formatted_text = (np.asarray([\"{0}\\n{1:.2f}\".format(\n",
        "text, data) for text, data in zip(text.flatten(), data.flatten())])).reshape(2, 2)\n",
        "\n",
        "# Plot heatmap\n",
        "fig, ax = plt.subplots(figsize=(12,8))\n",
        "sns.set(font_scale=1.5)\n",
        "ax = sns.heatmap(data_percent, annot=formatted_text, fmt=\"\", cmap='Blues', annot_kws={\"fontsize\":14, \"weight\":'bold'})\n",
        "ax.set_title(\"Confusion Matrix\", fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel(\"Actual\", fontsize=14, fontweight='bold')\n",
        "ax.set_ylabel(\"Predicted\", fontsize=14, fontweight='bold')\n"
      ],
      "metadata": {
        "id": "PCuDUUmGX_t7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predicting Test Images**"
      ],
      "metadata": {
        "id": "OOqdIhTYbhUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model weights\n",
        "\n",
        "model = load_model('Resources/Model/final_model_weights.hdf5')"
      ],
      "metadata": {
        "id": "RMUhGHErYE-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getprediction(img):\n",
        "    img = img_to_array(img)\n",
        "    img = img / 255\n",
        "    imshow(img)\n",
        "    plt.axis('off')\n",
        "    img = np.expand_dims(img,axis=0)\n",
        "    category = model.predict_classes(img)\n",
        "    answer = category[0]\n",
        "    probability = model.predict_proba(img)\n",
        "    # probability_results = probability[0][0]\n",
        "    if answer == 1:\n",
        "        print(f\"The image belongs to Recycle waste category, probability: {probability[0][1]}.\")\n",
        "    else:\n",
        "        print(f\"The image belongs to Organic waste category, probability: {probability[0][0]}.\")"
      ],
      "metadata": {
        "id": "XO15X0c_YJFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Case 1 - ORGANIC\n",
        "\n",
        "test_case1 = load_img(test_dir + '/O' + '/O_12568.jpg', target_size=(180,180))\n",
        "getprediction(test_case1)"
      ],
      "metadata": {
        "id": "pojgdl_NYL1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Case 2 - ORGANIC\n",
        "\n",
        "test_case2 = load_img(test_dir + '/O' + '/O_13185.jpg', target_size=(180,180))\n",
        "getprediction(test_case2)"
      ],
      "metadata": {
        "id": "aoPAGYxFYOr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Case 3 - ORGANIC\n",
        "\n",
        "test_case3 = load_img(test_dir + '/O' + '/O_13905.jpg', target_size=(180,180))\n",
        "getprediction(test_case3)"
      ],
      "metadata": {
        "id": "Tdou8ERJYRTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Case 4 - RECYCLED\n",
        "\n",
        "test_case4 = load_img(test_dir + '/R' + '/R_10000.jpg', target_size=(180,180))\n",
        "getprediction(test_case4)"
      ],
      "metadata": {
        "id": "SyaNIAURYTY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Case 5 - RECYCLED\n",
        "\n",
        "test_case5 = load_img(test_dir + '/R' + '/R_10398.jpg', target_size=(180,180))\n",
        "getprediction(test_case5)"
      ],
      "metadata": {
        "id": "_nM57Tr2YVlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Case 6 - RECYCLED\n",
        "test_case6 = load_img(test_dir + '/R' + '/R_10714.jpg', target_size=(180,180))\n",
        "getprediction(test_case6)"
      ],
      "metadata": {
        "id": "zg0_xAXhYXk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Case 7 - RECYCLED\n",
        "test_case7 = load_img(test_dir + '/R' + '/R_11107.jpg', target_size=(180,180))\n",
        "getprediction(test_case7)"
      ],
      "metadata": {
        "id": "8WHZOVz_YZgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Case 8 - RECYCLED\n",
        "test_case8 = load_img(test_dir + '/R' + '/R_10005.jpg', target_size=(180,180))\n",
        "getprediction(test_case8)"
      ],
      "metadata": {
        "id": "fGZVv3eIYZSO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1PEH8bBKRT1wrjo6fVfnWVNwwkDLJZvtv",
      "authorship_tag": "ABX9TyNgO5PltIIwNNbiTOBLD8Zw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}